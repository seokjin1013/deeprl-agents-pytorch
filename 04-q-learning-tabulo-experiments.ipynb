{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q-learning에서 고려해야할 점\n",
    "\n",
    "더 나은 해를 찾기 위한 exploit & exploration 전략\n",
    "* e-greedy: 매번 action을 결정할 때마다 항상 최적의 action만 취하지 않고 e의 확률로 무작위 action을 취함\n",
    "* decaying e-greedy: episode가 진행됨에 따라 q function이 학습되어감을 감안하여 e의 값을 점점 줄여가며 e-greedy를 적용\n",
    "* random noise: 항상 action을 정할 때 random noise를 주어 항상 가장 높은 확률의 action만 취하지는 않도록 함\n",
    "* decaying random noise: episode가 진행됨에 따라 q function이 학습되어감을 감안하여 random noise를 점점 줄여가며 e-greedy를 적용\n",
    "\n",
    "더 안정적이고 나은 해를 찾기 위한 discount 전략\n",
    "* discounted reward: 가까운 미래에 대한 보상을 먼 미래에 대한 보상보다 더 크게 생각함\n",
    "\n",
    "q-learning은 환경이 deterministic하고 observation space가 finite하다면 항상 converge함이 증명됨\n",
    "\n",
    "non-deterministic한 환경에서 해를 찾기 위한 전략\n",
    "* learning rate: 일정 비율만큼만 q를 학습시켜 강건하게 함\n",
    "\n",
    "환경이 non-deterministic하다면 learning rate를 활용했을 때 항상 converge함이 증명됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import ray.tune\n",
    "import ray.tune.search.optuna\n",
    "import ray.tune.schedulers.pb2\n",
    "import ray.air.integrations.wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning(ray.tune.Trainable):\n",
    "    def setup(self, config):\n",
    "        self.e_weight = config['e_weight']\n",
    "        self.e_bias = config['e_bias']\n",
    "        self.noise_amp = config['noise_amp']\n",
    "        self.discount = config['discount']\n",
    "        self.lr = config['lr']\n",
    "        self.env = gymnasium.make('FrozenLake-v1')\n",
    "        self.q = np.zeros((self.env.observation_space.n, self.env.action_space.n))\n",
    "        self.rewards = []\n",
    "    \n",
    "    def step(self):\n",
    "        u, info = self.env.reset()\n",
    "        reward = 0\n",
    "        step = 0\n",
    "        while True:\n",
    "            e = 1 / (step * self.e_weight + self.e_bias)\n",
    "            if np.random.random() < e:\n",
    "                action = self.env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(self.q[u, :] + np.random.random(self.env.action_space.n) * self.noise_amp)\n",
    "            v, r, terminated, truncated, info = self.env.step(action)\n",
    "            reward += r\n",
    "            step += 1\n",
    "            self.q[u, action] = (1 - self.lr) * self.q[u, action] + self.lr * (r + self.discount * np.max(self.q[v, :]))\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        self.rewards.append(reward)\n",
    "        return {'score': np.sum(self.rewards)}\n",
    "    \n",
    "    def save_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"q\")\n",
    "        self.q.dump(checkpoint_path)\n",
    "        return tmp_checkpoint_dir\n",
    "    \n",
    "    def load_checkpoint(self, tmp_checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(tmp_checkpoint_dir, \"q\")\n",
    "        self.q = np.load(checkpoint_path, allow_pickle=True)\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = ray.tune.Tuner(\n",
    "    QLearning,\n",
    "    tune_config=ray.tune.TuneConfig(\n",
    "        num_samples=-1,\n",
    "        scheduler = ray.tune.schedulers.pb2.PB2(\n",
    "            time_attr='time_total_s',\n",
    "            metric='score',\n",
    "            mode='max',\n",
    "            perturbation_interval=5.0,\n",
    "            hyperparam_bounds={\n",
    "                'e_weight': [0, 2],\n",
    "                'e_bias': [0, 500],\n",
    "                'noise_amp': [0, 1],\n",
    "                'discount': [0, 1],\n",
    "                'lr': [0, 1],\n",
    "            }\n",
    "        )\n",
    "    ), \n",
    "    run_config=ray.air.RunConfig(\n",
    "        callbacks=[\n",
    "            ray.air.integrations.wandb.WandbLoggerCallback(project='QLearning'),\n",
    "        ],\n",
    "        stop={\n",
    "            'training_iteration': 500,\n",
    "        },\n",
    "        checkpoint_config=ray.air.CheckpointConfig(\n",
    "            num_to_keep=3,\n",
    "            checkpoint_score_attribute='score',\n",
    "            checkpoint_score_order='max',\n",
    "            checkpoint_frequency=5,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:56:31,430\tINFO worker.py:1627 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-07-25 09:56:33,100\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      " /home/seokj/workspace/.venv/lib/python3.10/site-packages/ray/tune/tune.py:795: UserWarning:Consider boosting PBT performance by enabling `reuse_actors` as well as implementing `reset_config` for Trainable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-25 09:58:34</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:59.04        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.3/7.7 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  ... 11 more trials not shown (9 PENDING, 1 TERMINATED)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  discount</th><th style=\"text-align: right;\">   e_bias</th><th style=\"text-align: right;\">  e_weight</th><th style=\"text-align: right;\">       lr</th><th style=\"text-align: right;\">  noise_amp</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>QLearning_19293_00008</td><td>RUNNING   </td><td>172.26.215.93:84690</td><td style=\"text-align: right;\">  0.342404</td><td style=\"text-align: right;\">490.272  </td><td style=\"text-align: right;\"> 0.0939159</td><td style=\"text-align: right;\">0.612227 </td><td style=\"text-align: right;\">  0.892059 </td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">      0.529877  </td><td style=\"text-align: right;\">      5</td></tr>\n",
       "<tr><td>QLearning_19293_00009</td><td>RUNNING   </td><td>172.26.215.93:85091</td><td style=\"text-align: right;\">  0.448611</td><td style=\"text-align: right;\">357.19   </td><td style=\"text-align: right;\"> 1.29258  </td><td style=\"text-align: right;\">0.303155 </td><td style=\"text-align: right;\">  0.295359 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">      0.00365186</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>QLearning_19293_00010</td><td>RUNNING   </td><td>172.26.215.93:85093</td><td style=\"text-align: right;\">  0.91863 </td><td style=\"text-align: right;\"> 61.5705 </td><td style=\"text-align: right;\"> 1.27952  </td><td style=\"text-align: right;\">0.713519 </td><td style=\"text-align: right;\">  0.983653 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">      0.0104692 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>QLearning_19293_00011</td><td>RUNNING   </td><td>172.26.215.93:85096</td><td style=\"text-align: right;\">  0.533566</td><td style=\"text-align: right;\">216.329  </td><td style=\"text-align: right;\"> 0.29919  </td><td style=\"text-align: right;\">0.638748 </td><td style=\"text-align: right;\">  0.248776 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">      0.00630784</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>QLearning_19293_00013</td><td>RUNNING   </td><td>172.26.215.93:85127</td><td style=\"text-align: right;\">  0.890601</td><td style=\"text-align: right;\">471.822  </td><td style=\"text-align: right;\"> 1.96318  </td><td style=\"text-align: right;\">0.312419 </td><td style=\"text-align: right;\">  0.245912 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00014</td><td>RUNNING   </td><td>172.26.215.93:85128</td><td style=\"text-align: right;\">  0.900362</td><td style=\"text-align: right;\">137.849  </td><td style=\"text-align: right;\"> 0.293181 </td><td style=\"text-align: right;\">0.17519  </td><td style=\"text-align: right;\">  0.250292 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">      0.0184    </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>QLearning_19293_00015</td><td>RUNNING   </td><td>172.26.215.93:85461</td><td style=\"text-align: right;\">  0.737518</td><td style=\"text-align: right;\">280.687  </td><td style=\"text-align: right;\"> 1.04735  </td><td style=\"text-align: right;\">0.562984 </td><td style=\"text-align: right;\">  0.277247 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">      0.00400329</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>QLearning_19293_00012</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.62004 </td><td style=\"text-align: right;\">210.363  </td><td style=\"text-align: right;\"> 0.665454 </td><td style=\"text-align: right;\">0.307021 </td><td style=\"text-align: right;\">  0.193716 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00016</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.406881</td><td style=\"text-align: right;\">136.438  </td><td style=\"text-align: right;\"> 1.05413  </td><td style=\"text-align: right;\">0.635878 </td><td style=\"text-align: right;\">  0.0627093</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00017</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.384536</td><td style=\"text-align: right;\">  4.17258</td><td style=\"text-align: right;\"> 1.75333  </td><td style=\"text-align: right;\">0.66518  </td><td style=\"text-align: right;\">  0.66244  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00018</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.69245 </td><td style=\"text-align: right;\"> 24.6911 </td><td style=\"text-align: right;\"> 1.43284  </td><td style=\"text-align: right;\">0.606025 </td><td style=\"text-align: right;\">  0.296839 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00019</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.250649</td><td style=\"text-align: right;\">345.875  </td><td style=\"text-align: right;\"> 0.924682 </td><td style=\"text-align: right;\">0.373297 </td><td style=\"text-align: right;\">  0.878741 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00020</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.741598</td><td style=\"text-align: right;\">468.393  </td><td style=\"text-align: right;\"> 1.73974  </td><td style=\"text-align: right;\">0.0177563</td><td style=\"text-align: right;\">  0.0577191</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00021</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">  0.949297</td><td style=\"text-align: right;\"> 11.0393 </td><td style=\"text-align: right;\"> 1.34156  </td><td style=\"text-align: right;\">0.517688 </td><td style=\"text-align: right;\">  0.951024 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>QLearning_19293_00000</td><td>TERMINATED</td><td>172.26.215.93:82461</td><td style=\"text-align: right;\">  0.114419</td><td style=\"text-align: right;\">179.091  </td><td style=\"text-align: right;\"> 0.793275 </td><td style=\"text-align: right;\">0.837539 </td><td style=\"text-align: right;\">  0.592547 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.455641  </td><td style=\"text-align: right;\">      7</td></tr>\n",
       "<tr><td>QLearning_19293_00001</td><td>TERMINATED</td><td>172.26.215.93:82462</td><td style=\"text-align: right;\">  0.614208</td><td style=\"text-align: right;\">439.331  </td><td style=\"text-align: right;\"> 1.24642  </td><td style=\"text-align: right;\">0.609398 </td><td style=\"text-align: right;\">  0.339436 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.455195  </td><td style=\"text-align: right;\">      4</td></tr>\n",
       "<tr><td>QLearning_19293_00002</td><td>TERMINATED</td><td>172.26.215.93:82463</td><td style=\"text-align: right;\">  0.377698</td><td style=\"text-align: right;\">117.437  </td><td style=\"text-align: right;\"> 0.359358 </td><td style=\"text-align: right;\">0.735643 </td><td style=\"text-align: right;\">  0.499544 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.486526  </td><td style=\"text-align: right;\">      5</td></tr>\n",
       "<tr><td>QLearning_19293_00003</td><td>TERMINATED</td><td>172.26.215.93:82464</td><td style=\"text-align: right;\">  0.874134</td><td style=\"text-align: right;\">309.466  </td><td style=\"text-align: right;\"> 0.262147 </td><td style=\"text-align: right;\">0.276428 </td><td style=\"text-align: right;\">  0.996771 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.545912  </td><td style=\"text-align: right;\">     10</td></tr>\n",
       "<tr><td>QLearning_19293_00004</td><td>TERMINATED</td><td>172.26.215.93:82465</td><td style=\"text-align: right;\">  0.294072</td><td style=\"text-align: right;\"> 31.2535 </td><td style=\"text-align: right;\"> 1.41563  </td><td style=\"text-align: right;\">0.146605 </td><td style=\"text-align: right;\">  0.0732468</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.494533  </td><td style=\"text-align: right;\">      8</td></tr>\n",
       "<tr><td>QLearning_19293_00005</td><td>TERMINATED</td><td>172.26.215.93:82466</td><td style=\"text-align: right;\">  0.185549</td><td style=\"text-align: right;\"> 77.7104 </td><td style=\"text-align: right;\"> 0.959224 </td><td style=\"text-align: right;\">0.282937 </td><td style=\"text-align: right;\">  0.645097 </td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.446376  </td><td style=\"text-align: right;\">      3</td></tr>\n",
       "<tr><td>QLearning_19293_00006</td><td>TERMINATED</td><td>172.26.215.93:82467</td><td style=\"text-align: right;\">  0.663602</td><td style=\"text-align: right;\"> 34.3858 </td><td style=\"text-align: right;\"> 1.96052  </td><td style=\"text-align: right;\">0.0944689</td><td style=\"text-align: right;\">  0.0886395</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">      0.53046   </td><td style=\"text-align: right;\">     12</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:56:35,068\tINFO wandb.py:320 -- Already logged into W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  score</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">   trial_id</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>QLearning_19293_00000</td><td>2023-07-25_09-58-04</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82461</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">          0.455641  </td><td style=\"text-align: right;\">       0.000976562</td><td style=\"text-align: right;\">    0.455641  </td><td style=\"text-align: right;\"> 1690246684</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00000</td></tr>\n",
       "<tr><td>QLearning_19293_00001</td><td>2023-07-25_09-58-08</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82462</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">          0.455195  </td><td style=\"text-align: right;\">       0.0010097  </td><td style=\"text-align: right;\">    0.455195  </td><td style=\"text-align: right;\"> 1690246688</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00001</td></tr>\n",
       "<tr><td>QLearning_19293_00002</td><td>2023-07-25_09-58-12</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82463</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">          0.486526  </td><td style=\"text-align: right;\">       0.000966072</td><td style=\"text-align: right;\">    0.486526  </td><td style=\"text-align: right;\"> 1690246692</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00002</td></tr>\n",
       "<tr><td>QLearning_19293_00003</td><td>2023-07-25_09-58-10</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82464</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">          0.545912  </td><td style=\"text-align: right;\">       0.00057888 </td><td style=\"text-align: right;\">    0.545912  </td><td style=\"text-align: right;\"> 1690246690</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00003</td></tr>\n",
       "<tr><td>QLearning_19293_00004</td><td>2023-07-25_09-58-09</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82465</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">          0.494533  </td><td style=\"text-align: right;\">       0.000878811</td><td style=\"text-align: right;\">    0.494533  </td><td style=\"text-align: right;\"> 1690246689</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00004</td></tr>\n",
       "<tr><td>QLearning_19293_00005</td><td>2023-07-25_09-58-00</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82466</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">          0.446376  </td><td style=\"text-align: right;\">       0.000694275</td><td style=\"text-align: right;\">    0.446376  </td><td style=\"text-align: right;\"> 1690246680</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00005</td></tr>\n",
       "<tr><td>QLearning_19293_00006</td><td>2023-07-25_09-58-04</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82467</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">          0.53046   </td><td style=\"text-align: right;\">       0.00168705 </td><td style=\"text-align: right;\">    0.53046   </td><td style=\"text-align: right;\"> 1690246684</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00006</td></tr>\n",
       "<tr><td>QLearning_19293_00007</td><td>2023-07-25_09-57-59</td><td>True  </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       500</td><td>172.26.215.93</td><td style=\"text-align: right;\">82468</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">          0.438363  </td><td style=\"text-align: right;\">       0.000495911</td><td style=\"text-align: right;\">    0.438363  </td><td style=\"text-align: right;\"> 1690246679</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">19293_00007</td></tr>\n",
       "<tr><td>QLearning_19293_00008</td><td>2023-07-25_09-58-34</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                       186</td><td>172.26.215.93</td><td style=\"text-align: right;\">84690</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">          0.531027  </td><td style=\"text-align: right;\">       0.00115037 </td><td style=\"text-align: right;\">    0.531027  </td><td style=\"text-align: right;\"> 1690246714</td><td style=\"text-align: right;\">                 186</td><td style=\"text-align: right;\">19293_00008</td></tr>\n",
       "<tr><td>QLearning_19293_00009</td><td>2023-07-25_09-58-24</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td>172.26.215.93</td><td style=\"text-align: right;\">85091</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">          0.00365186</td><td style=\"text-align: right;\">       0.00365186 </td><td style=\"text-align: right;\">    0.00365186</td><td style=\"text-align: right;\"> 1690246704</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">19293_00009</td></tr>\n",
       "<tr><td>QLearning_19293_00010</td><td>2023-07-25_09-58-27</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         8</td><td>172.26.215.93</td><td style=\"text-align: right;\">85093</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">          0.010962  </td><td style=\"text-align: right;\">       0.000492811</td><td style=\"text-align: right;\">    0.010962  </td><td style=\"text-align: right;\"> 1690246707</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">19293_00010</td></tr>\n",
       "<tr><td>QLearning_19293_00011</td><td>2023-07-25_09-58-18</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td>172.26.215.93</td><td style=\"text-align: right;\">85096</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">          0.00525069</td><td style=\"text-align: right;\">       0.00525069 </td><td style=\"text-align: right;\">    0.00525069</td><td style=\"text-align: right;\"> 1690246698</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">19293_00011</td></tr>\n",
       "<tr><td>QLearning_19293_00014</td><td>2023-07-25_09-58-27</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         1</td><td>172.26.215.93</td><td style=\"text-align: right;\">85128</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">          0.00326109</td><td style=\"text-align: right;\">       0.00326109 </td><td style=\"text-align: right;\">    0.00326109</td><td style=\"text-align: right;\"> 1690246707</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">19293_00014</td></tr>\n",
       "<tr><td>QLearning_19293_00015</td><td>2023-07-25_09-58-27</td><td>False </td><td>DESKTOP-0P789CI</td><td style=\"text-align: right;\">                         3</td><td>172.26.215.93</td><td style=\"text-align: right;\">85461</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">          0.00573802</td><td style=\"text-align: right;\">       0.00173473 </td><td style=\"text-align: right;\">    0.00573802</td><td style=\"text-align: right;\"> 1690246707</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">19293_00015</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "2023-07-25 09:56:51,813\tWARNING worker.py:2019 -- WARNING: 32 PYTHON worker processes have been started on node: b8230e916ad7b9631f02f14814b85ab2c22a87d05aa69de051bc1a57 with address: 172.26.215.93. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00002_2_2023-07-25_09-56-35/wandb/run-20230725_095651-19293_00002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Syncing run QLearning_19293_00002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00002\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:  $ pip install wandb --upgrade\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: Tracking run with wandb version 0.15.4\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00004_4_2023-07-25_09-56-35/wandb/run-20230725_095656-19293_00004\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: Syncing run QLearning_19293_00004\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00004\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:  $ pip install wandb --upgrade\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Tracking run with wandb version 0.15.4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00000_0_2023-07-25_09-56-35/wandb/run-20230725_095704-19293_00000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Syncing run QLearning_19293_00000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "2023-07-25 09:58:01,406\tWARNING worker.py:2019 -- WARNING: 40 PYTHON worker processes have been started on node: b8230e916ad7b9631f02f14814b85ab2c22a87d05aa69de051bc1a57 with address: 172.26.215.93. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: iterations_since_restore ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:                    score ▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:       time_since_restore ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:         time_this_iter_s ▂▂▁▃▂▁▁▅▂▂█▂▂▁▄▄▅▅▄▃▁▂▂▁▂▁▂▁▂▂▃▂▇▃▂▂▂▂▂▃\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:             time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:                timestamp ▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:       training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: iterations_since_restore 500\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:                    score 7.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:       time_since_restore 0.43836\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:         time_this_iter_s 0.0005\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:             time_total_s 0.43836\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:                timestamp 1690246679\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb:       training_iteration 500\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: 🚀 View run QLearning_19293_00007 at: https://wandb.ai/seokjin/QLearning/runs/19293_00007\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82909)\u001b[0m wandb: Find logs at: ./wandb/run-20230725_095655-19293_00007/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82905)\u001b[0m wandb:                    score ▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆█████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82905)\u001b[0m wandb:       time_since_restore ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82905)\u001b[0m wandb:         time_this_iter_s ▃▁▃▃▁▁▁▃▂▃▄▃▅▁▁▁▁▃▃▃▂▁▁▂▃▂▂▄▄▂▂▁▃▂▁▄▃█▂▂\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82905)\u001b[0m wandb:             time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82905)\u001b[0m wandb:                timestamp ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: Waiting for W&B process to finish... (success).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: - 0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2023-07-25 09:58:07,944\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.618 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:07,949\tWARNING util.py:315 -- The `process_trial_result` operation took 2.623 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:07,951\tWARNING util.py:315 -- Processing trial results took 2.625 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:07,954\tWARNING util.py:315 -- The `process_trial_result` operation took 2.628 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:                    score ▁▁▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▅▆▆▇▇▇▇████████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:       time_since_restore ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:         time_this_iter_s ▂▁▁▃▄▅▃▃▂▄▄▂▂█▂▂▂▃▁▄▁▇▃▆▄▁▂▃▆▂▃▃▄▁▂▃▂▄▃▁\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:             time_total_s ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:                timestamp ▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Run history:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: iterations_since_restore ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:       training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Run summary:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: iterations_since_restore 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:                    score 7.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:       time_since_restore 0.45564\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:         time_this_iter_s 0.00098\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:             time_total_s 0.45564\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:                timestamp 1690246684\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb:       training_iteration 500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: 🚀 View run QLearning_19293_00000 at: https://wandb.ai/seokjin/QLearning/runs/19293_00000\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83698)\u001b[0m wandb: Find logs at: ./wandb/run-20230725_095704-19293_00000/logs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb:                    score ▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb:       time_since_restore ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb:         time_this_iter_s ▂▁▇▁▂▆▃▁▃▃▂▆▂▅▂▂▂▂▃▃▁▃▅▃▂▂▂▂█▃▆▃▇▃▁▂▃▃▂▅\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb:             time_total_s ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb:                timestamp ▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: Waiting for W&B process to finish... (success).\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82916)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: iterations_since_restore ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:                    score ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆█\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:       time_since_restore ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:         time_this_iter_s ▂▁▃▂▁▁▂▂▂▁▃▆▂▃▃▃▄▃▃▂▁▂▂▁█▂▃▂▁▂▂▂▂▂▂▁▂▂▂▁\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:             time_total_s ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:                timestamp ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:       training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: iterations_since_restore 500\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:                    score 4.0\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:       time_since_restore 0.4552\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:         time_this_iter_s 0.00101\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:             time_total_s 0.4552\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:                timestamp 1690246688\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb:       training_iteration 500\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: 🚀 View run QLearning_19293_00001 at: https://wandb.ai/seokjin/QLearning/runs/19293_00001\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82913)\u001b[0m wandb: Find logs at: ./wandb/run-20230725_095656-19293_00001/logs\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00008_8_2023-07-25_09-56-35/wandb/run-20230725_095811-19293_00008\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: Syncing run QLearning_19293_00008\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=84800)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00008\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:                    score ▁▁▁▂▂▂▂▂▂▂▂▂▃▃▅▅▅▅▅▅▅▅▅▅▇▇██████████████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:       time_since_restore ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:         time_this_iter_s ▂▁▁▁▅▃▁▂▂▂▂▂▃▂▁▁▃▃▅▂▂▁▆▂▃▃█▃▃▃▃▁▂▃▁▂▂▂▃▂\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:             time_total_s ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82960)\u001b[0m wandb:                timestamp ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Waiting for W&B process to finish... (success).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb:                    score ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▆▇▇▇▇▇▇▇▇▇▇▇▇█████████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb:       time_since_restore ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb:         time_this_iter_s ▂▃▁▃▃▄▂▄▂▆▃▃▃▂▆▃▃█▂▁▄▁▄▄▁▂▂▁▂▂▄▁▃▁▅▅▂▄▅▄\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb:             time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=83370)\u001b[0m wandb:                timestamp ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:                    score ▁▁▁▁▂▂▂▂▂▂▄▄▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:       time_since_restore ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:         time_this_iter_s ▃▂▅▂▂▂▂▃▁▂▂▁▃▆▄▂▂▃▃▂▂▂▄▁▃▄▂▂▂▃█▃▄▂▁█▃▃▂▃\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:             time_total_s ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:                timestamp ▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██\n",
      "2023-07-25 09:58:20,895\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.837 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:20,898\tWARNING util.py:315 -- The `process_trial_result` operation took 2.841 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:20,899\tWARNING util.py:315 -- Processing trial results took 2.842 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:20,900\tWARNING util.py:315 -- The `process_trial_result` operation took 2.843 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: \\ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: - 0.002 MB of 0.007 MB uploaded (0.000 MB deduped)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: \u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Run history:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: iterations_since_restore ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:       training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Run summary:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: iterations_since_restore 500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:                    score 5.0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:       time_since_restore 0.48653\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:         time_this_iter_s 0.00097\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:             time_total_s 0.48653\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:                timestamp 1690246692\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb:       training_iteration 500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: 🚀 View run QLearning_19293_00002 at: https://wandb.ai/seokjin/QLearning/runs/19293_00002\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=82811)\u001b[0m wandb: Find logs at: ./wandb/run-20230725_095651-19293_00002/logs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2023-07-25 09:58:24,494\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 3.433 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:24,500\tWARNING util.py:315 -- The `process_trial_result` operation took 3.439 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:24,503\tWARNING util.py:315 -- Processing trial results took 3.442 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:24,504\tWARNING util.py:315 -- The `process_trial_result` operation took 3.444 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: Tracking run with wandb version 0.15.4\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00011_11_2023-07-25_09-56-35/wandb/run-20230725_095824-19293_00011\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: Syncing run QLearning_19293_00011\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85502)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00011\n",
      "2023-07-25 09:58:27,076\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.447 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:27,078\tWARNING util.py:315 -- The `process_trial_result` operation took 2.450 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:27,081\tWARNING util.py:315 -- Processing trial results took 2.453 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:27,082\tWARNING util.py:315 -- The `process_trial_result` operation took 2.454 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: - Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: \\ Waiting for wandb.init()...\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: Currently logged in as: seokjin. Use `wandb login --relogin` to force relogin\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2023-07-25 09:58:31,650\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 4.160 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:31,654\tWARNING util.py:315 -- The `process_trial_result` operation took 4.164 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:31,657\tWARNING util.py:315 -- Processing trial results took 4.167 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:31,661\tWARNING util.py:315 -- The `process_trial_result` operation took 4.171 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: wandb version 0.15.6 is available!  To upgrade, please run:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb:  $ pip install wandb --upgrade\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: Tracking run with wandb version 0.15.4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: Run data is saved locally in /home/seokj/ray_results/QLearning_2023-07-25_09-56-28/QLearning_19293_00015_15_2023-07-25_09-56-35/wandb/run-20230725_095827-19293_00015\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: Syncing run QLearning_19293_00015\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/seokjin/QLearning\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WandbLoggingActor pid=85638)\u001b[0m wandb: 🚀 View run at https://wandb.ai/seokjin/QLearning/runs/19293_00015\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2023-07-25 09:58:34,088\tWARNING util.py:315 -- The `callbacks.on_trial_result` operation took 2.223 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:34,090\tWARNING util.py:315 -- The `process_trial_result` operation took 2.226 s, which may be a performance bottleneck.\n",
      "2023-07-25 09:58:34,093\tWARNING util.py:315 -- Processing trial results took 2.229 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-07-25 09:58:34,095\tWARNING util.py:315 -- The `process_trial_result` operation took 2.231 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-07-25 09:59:31,341 E 82067 82067] (raylet) node_manager.cc:3069: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: b8230e916ad7b9631f02f14814b85ab2c22a87d05aa69de051bc1a57, IP: 172.26.215.93) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.26.215.93`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
